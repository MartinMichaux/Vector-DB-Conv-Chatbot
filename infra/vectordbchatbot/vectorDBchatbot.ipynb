{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import ElasticsearchStore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "index_name = \"test_index\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "    es_cloud_id=os.environ[\"ELASTICSEARCH_CLOUD_ID\"],\n",
    "    es_api_key=os.environ[\"ELASTICSEARCH_API_KEY\"],\n",
    "    index_name= index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vector_store.as_retriever( search_type=\"similarity\",  # Also test \"similarity\", \"mmr\"\n",
    "    search_kwargs={\"k\": 5},)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a friendly assistant for question-answering tasks about business reports of different companies. Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer or don't have to use any context, just say that you don't know. Be as verbose and educational in your response as possible.\n",
    "\n",
    "context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use retriever to get the top k similar documents\n",
    "answer = rag_chain_with_source.invoke(\"What is the name of the CEO of McKinsey?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Many McKinsey colleagues provided helpful input \\nand\\xa0advice, including Lukasz\\xa0Abramowicz, Navtez\\xa0Bal, \\nJim\\xa0Banaszak, Jose Luis\\xa0Blanco, João\\xa0Pedro\\xa0Branco, \\nOlivier\\xa0Cazeaux, Shankar\\xa0Chandrasekaran, \\nRoberto\\xa0Charron, Rocco\\xa0Colasante, Silvia\\xa0Costa, \\nOlivier d’Hossche, Arlindo Eira\\xa0Filho, Fabio\\xa0Ferri, \\nNicklas\\xa0Garemo, Joao\\xa0Goncalves, Jason\\xa0Green, \\nDavide\\xa0Gronchi, Tony\\xa0Hansen, Jeff\\xa0Hart, TG\\xa0Jayanth, \\nIvan\\xa0Jelic, Priyanka\\xa0Kamra, Kate\\xa0Kang, Vikram\\xa0Kapur, \\nAmit\\xa0Khera, Jan\\xa0Koeleman, Mark\\xa0Kuvshinikov, \\nAntoine\\xa0Lagasse, Alison\\xa0Lai, Adi\\xa0Leviatan, \\nCarsten\\xa0Lotz, Tim\\xa0McManus, Parker\\xa0Meeks, \\nCarlos\\xa0Mendes, Gerhard\\xa0Nel, Kevin\\xa0Nobels, \\nRobert\\xa0Palter, Prakash\\xa0Parbhoo, Matthew\\xa0Parsons, \\nNikhil\\xa0Patel, Shannon\\xa0Peloquin, Frederic\\xa0Remond, \\nStuart\\xa0Shilson, Suveer\\xa0Sinha, Erik\\xa0Sjodin, \\nTiago\\xa0Sousa, Venkataramamoorthy\\xa0Sreeramagiri, \\nGernot\\xa0Strube, Jordi\\xa0Suarez, Michael\\xa0Tecza, \\nFrank von\\xa0Willert, Simon\\xa0Webb, Angela\\xa0Woods, \\nCathy\\xa0Wright, Edward\\xa0Zaayman, Paul\\xa0Zarba, and \\nHomayoun\\xa0Zarrinkoub.', metadata={'id': 'tests/sample\\\\mgi-reinventing-construction-a-route-to-higher-productivity-full-report.pdf_18', 'source': 'tests/sample\\\\mgi-reinventing-construction-a-route-to-higher-productivity-full-report.pdf', 'page': 3}),\n",
       "  Document(page_content='McKinsey analysis', metadata={'id': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf_150', 'source': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf', 'page': 51}),\n",
       "  Document(page_content='McKinsey analysis', metadata={'id': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf_449', 'source': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf', 'page': 169}),\n",
       "  Document(page_content='McKinsey analysis', metadata={'id': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf_135', 'source': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf', 'page': 45}),\n",
       "  Document(page_content='McKinsey analysis', metadata={'id': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf_205', 'source': 'tests/sample\\\\mckinsey-tech-trends-outlook-2022-full-report.pdf', 'page': 71})],\n",
       " 'question': 'What is the name of the CEO of McKinsey?',\n",
       " 'answer': \"The given context does not provide any information about the name of the CEO of McKinsey. Therefore, I don't know the answer to this question.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic interface (using Gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Response runtime: 5.386956691741943 seconds\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# Define chat interface\n",
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "    chat_history = []\n",
    "    \n",
    "    def respond(question, chat_history):\n",
    "        start_time = time.time()  # Record start time\n",
    "        \n",
    "        result =rag_chain_with_source.invoke(question)\n",
    "        answer = result[\"answer\"]      \n",
    "\n",
    "        sources = \"relevant documentation:\\n\"\n",
    "        for d in result['context']:\n",
    "            sources += str(d.metadata['source']) + \" page \" + str(d.metadata['page']) + \"\\n\"\n",
    "        answer += \"\\n\\n\" + sources\n",
    "        \n",
    "        # Append user message and response to chat history\n",
    "        chat_history.append((question, answer))\n",
    "        \n",
    "        end_time = time.time()  # Record end time\n",
    "        runtime = end_time - start_time        \n",
    "        print(\"---------Response runtime:\", runtime, \"seconds\")  # Print the runtime\n",
    "\n",
    "        return \"\", chat_history\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot], queue=False)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
