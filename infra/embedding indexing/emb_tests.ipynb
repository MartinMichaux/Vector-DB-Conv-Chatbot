{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ct3OzO48afwl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain.document_loaders import WikipediaLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJSbT2Qxbc45"
      },
      "source": [
        "## chunk text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y5QpJu9LcHqj"
      },
      "outputs": [],
      "source": [
        "# pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_VEvjBNPbjlu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "from typing import List\n",
        "from multiprocessing import Pool\n",
        "from tqdm import tqdm\n",
        "from langchain.document_loaders import CSVLoader, PyPDFLoader, Docx2txtLoader\n",
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SMVYrtaKbfqd"
      },
      "outputs": [],
      "source": [
        "# Map file extensions to document loaders and their arguments\n",
        "loaders_mapping = {\n",
        "    \".csv\": CSVLoader,\n",
        "    \".docx\": Docx2txtLoader,\n",
        "    \".pdf\": PyPDFLoader\n",
        "}\n",
        "\n",
        "def load_document(file_path: str) -> Document:\n",
        "    ## Find extension of the file\n",
        "    ext = \".\" + file_path.rsplit(\".\", 1)[-1]\n",
        "    if ext in loaders_mapping:\n",
        "        # Find the appropriate loader class\n",
        "        loader_class = loaders_mapping[ext]\n",
        "        # Invoke the instance of document loader\n",
        "        loader = loader_class(file_path)\n",
        "        ## Return the loaded document\n",
        "        return loader.load()\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file extension '{ext}'\")\n",
        "\n",
        "def load_documents(source_dir: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Loads all documents from the source documents directory\n",
        "    \"\"\"\n",
        "    all_files = []\n",
        "    for ext in loaders_mapping:\n",
        "        #Find all the files within source documents which matches the extensions in loaders_mapping\n",
        "        all_files.extend(\n",
        "            glob.glob(os.path.join(source_dir, f\"**/*{ext}\"), recursive=True)\n",
        "        )\n",
        "\n",
        "    ## Spinning up resource pool\n",
        "    with Pool(processes=os.cpu_count()) as pool:\n",
        "        results = []\n",
        "        with tqdm(total=len(all_files), desc='Loading new documents', ncols=80) as pbar:\n",
        "            # Load each document from filtered files list using load_single_document function\n",
        "            for i, doc in enumerate(pool.imap_unordered(load_document, all_files)):\n",
        "                results.extend(doc)\n",
        "                pbar.update()\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR62wtPxboAp",
        "outputId": "31cad159-f7f9-4aab-ed11-57677734f70d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading new documents: 100%|██████████████████████| 1/1 [00:24<00:00, 24.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of loaded documents: 88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loaded_documents = load_documents(\"./sample\")\n",
        "print(f\"Length of loaded documents: {len(loaded_documents)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60KpiOSvcD8v",
        "outputId": "8ff95db1-32f4-4bf4-90f8-a5e813b56d06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 747, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 684, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 543, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 937, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 676, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1151, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 636, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 684, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 870, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 605, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 616, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 670, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 633, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3846, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 575, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 621, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 684, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 541, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 569, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 517, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 555, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 734, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 560, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 587, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 524, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 531, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 647, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 820, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 581, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 644, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 890, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 606, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 901, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 746, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 639, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 573, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 819, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 554, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 798, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1037, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 932, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 645, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1207, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 520, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 638, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 965, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 687, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 969, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 568, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 711, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 870, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 568, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1556, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 628, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 632, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 928, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 574, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 587, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1305, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 538, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 801, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 523, which is longer than the specified 512\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 635, which is longer than the specified 512\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "830"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "\n",
        "# split docs in chunks\n",
        "text_splitter = SpacyTextSplitter(\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=64\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(loaded_documents)\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9HuUi8lcmaI"
      },
      "source": [
        "## Neo4j vector index\n",
        "\n",
        "https://python.langchain.com/docs/integrations/vectorstores/neo4jvector\n",
        "\n",
        "https://github.com/sauravjoshi23/towards-agi/blob/main/retrieval%20augmented%20generation/integrated-qa-neo4j-langchain.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZYPI8UOeuRz"
      },
      "outputs": [],
      "source": [
        "# %pip install langchain openai tiktoken neo4j python-dotenv transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn2SrSLYepR0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain.document_loaders import WikipediaLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0WtjGEh-a_yq"
      },
      "outputs": [],
      "source": [
        "# Instantiate Neo4j vector from documents\n",
        "neo4j_vector = Neo4jVector.from_documents(\n",
        "    documents,\n",
        "    OpenAIEmbeddings(),\n",
        "    url=os.environ[\"NEO4J_URI\"],\n",
        "    username=os.environ[\"NEO4J_USERNAME\"],\n",
        "    password=os.environ[\"NEO4J_PASSWORD\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tWoEhzddKiL",
        "outputId": "93899a01-5aba-47c4-e660-bc03e0dd482f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.949164628982544\n",
            "The Procter & Gamble Company • 73\n",
            "Company Leadership\n",
            "Jon R. Moeller\n",
            "Chairman of the Board, President and Chief Executive Officer\n",
            "Shailesh G. Jejurikar\n",
            "Chief Operating Officer\n",
            "Gary Coombe\n",
            "Chief Executive Officer – Grooming\n",
            "Executive Sponsor – Corporate Wellbeing\n",
            "Jennifer Davis\n",
            "Chief Executive Officer –  \n",
            "Health CareMa.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.9390952587127686\n",
            "20        The Procter & Gamble Company\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.9373219013214111\n",
            "72 • The Procter & Gamble Company\n",
            "Board of Directors\n",
            "B. Marc Allen\n",
            "Chief Strategy Officer and Senior Vice President of \n",
            "Strategy and Corporate Development at The Boeing Company (aerospace, commercial jetliners, and military defense systems).\n",
            "\n",
            "Director since 2021.\n",
            "\n",
            "Age 50.\n",
            "\n",
            "\n",
            "Sheila Bonini\n",
            "Senior Vice President of Private Sector Engagement at the World Wildlife Fund (nonprofit wildlife conservation organization).\n",
            "\n",
            "Director since April 2023.\n",
            "\n",
            "Age 59.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the name of the CEO of Procter and Gamble?\"\n",
        "neo4j_docs_with_score = neo4j_vector.similarity_search_with_score(query, k=3)\n",
        "\n",
        "for doc, score in neo4j_docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEu6DFgdehhD"
      },
      "source": [
        "## FAISS vector index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CmVqvIjif1ym"
      },
      "outputs": [],
      "source": [
        "# !pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rPZCOco5ek1K"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qU3p_McJfH8B"
      },
      "outputs": [],
      "source": [
        "FAISS_vector = FAISS.from_documents(documents,OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79jhufBefxJh",
        "outputId": "60a8ab63-d3f4-411c-817b-b790406a707c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.949164628982544\n",
            "The Procter & Gamble Company • 73\n",
            "Company Leadership\n",
            "Jon R. Moeller\n",
            "Chairman of the Board, President and Chief Executive Officer\n",
            "Shailesh G. Jejurikar\n",
            "Chief Operating Officer\n",
            "Gary Coombe\n",
            "Chief Executive Officer – Grooming\n",
            "Executive Sponsor – Corporate Wellbeing\n",
            "Jennifer Davis\n",
            "Chief Executive Officer –  \n",
            "Health CareMa.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.9390952587127686\n",
            "20        The Procter & Gamble Company\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.9373219013214111\n",
            "72 • The Procter & Gamble Company\n",
            "Board of Directors\n",
            "B. Marc Allen\n",
            "Chief Strategy Officer and Senior Vice President of \n",
            "Strategy and Corporate Development at The Boeing Company (aerospace, commercial jetliners, and military defense systems).\n",
            "\n",
            "Director since 2021.\n",
            "\n",
            "Age 50.\n",
            "\n",
            "\n",
            "Sheila Bonini\n",
            "Senior Vice President of Private Sector Engagement at the World Wildlife Fund (nonprofit wildlife conservation organization).\n",
            "\n",
            "Director since April 2023.\n",
            "\n",
            "Age 59.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the name of the CEO of Procter and Gamble?\"\n",
        "FAISS_docs_with_score = FAISS_vector.similarity_search_with_score(query, k=3)\n",
        "\n",
        "for doc, score in FAISS_docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ElasticSearch embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.embeddings.elasticsearch import ElasticsearchEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "document_embeddings = embeddings.embed_documents(documents)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
